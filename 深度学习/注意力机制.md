# 注意力机制

关键在于如何衡量q，k的相似性

## 加性注意力

```math
score(q, k) = v^Ttanh(W_qq+W_kk)
```

不是直接计算差值，而是把q 和 k线性映射后再通过非线性激活融合

差值本质上是一种线性变换的特例

## 缩放点击注意力

用内积衡量相似性

缩放点积注意力：Scaled Dot-Product Attention，Transformer 架构核心组件之一，用于计算序列中元素之间的关系和重要性

- 核心思想：通过计算查询向量（Query）、键向量（Key）和值向量（Value）之间的关系，来决定如何从值向量中加权组合出一个输出向量
- 具体步骤：

  - 三个输入矩阵：

    - **Query（Q）** ：表示当前要关注的元素
    - **Key（K）** ：表示所有元素的特征
    - **Value（V）** ：与 Key 相对应的元素内容
  - **计算点积**：对每个 Query 向量与所有 Key 向量进行点积，得到一个表示相关性或注意力分数的矩阵
  - **缩放**：将上述分数除以一个缩放因子，通常是 Key 向量的维度的平方根。这是为了防止在计算 softmax 时，点积结果过大导致梯度消失的问题
  - **Softmax**：对归一化后的分数应用 softmax 函数，得到注意力权重，表示各个 Key 对当前 Query 的重要性
  - **加权求和**：用计算得到的注意力权重对 Value 向量进行加权求和，最终得到输出
- 数学表达

  $$
  Attention(Q, K, V) = softmax( \frac{QK^T}{\sqrt {d_k}}) V
  $$

‍

输入 E（每个词的向量）**通过三个不同的线性变换矩阵**生成查询（Query）、键（Key）、值（Value）矩阵:

$Q = EW^Q, K = EW^K, V = EW^V$

这里的W都是可以**学习的参数矩阵**，作用就是从原始表示 E 中学习出适合注意力机制使用的 Q、K、V 表示

$$
head_i = Attention(EW_iQ, EW_iK, EW_iV)
$$

变成

$$
head_i = Attention(QW_iQ, KW_iK, VW_iV)
$$

Q、K、V 只是中间变量，怎么表示都可以，只要数学等价

- 在 **Encoder 自注意力**中，Q\=K\=V\=E
- 在 **Encoder-Decoder attention**中，Q\=decoder hidden，而 K,V\=encoder output

# Transformer

前馈网络功能

在标准Transformer中，每个Encoder/Decoder层包含：

- Multi-Head Attention
- **Feed-Forward Network (FFN)**
- 残差 + LayerNorm

FFN结构：

```math
FFN(x) = max(0, xW_1 + b_1)W_2+b_2
```



通常：

dmodel→W1dff→W2dmodel

典型维度：dmodel=512, dff=2048。

**核心功能：**

1. **非线性映射，提升表达能力**
    - Multi-head attention是线性的，无法捕获复杂特征。
    - FFN加ReLU是通用近似器，可学习更复杂的特征变换。
2. **改变维度，提升特征交互能力**
    - 通常会先升维（512 → 2048），在高维空间做非线性变换，再降回去。
3. **每个位置独立变换，不引入跨位置交互**
    - Attention处理“位置间关系”，FFN处理“单位置特征”。
    - 这样可以分解建模任务：**依赖关系**由Attention建模，**位置内特征提取**由FFN完成。

------

## **2. 为什么叫“基于位置的”前馈网络（Position-wise FFN）？**

这里的 **Position-wise** 并不是指“位置有关”，而是指：

- **对每个位置的表示向量独立应用相同的FFN**。

- 假设输入序列是 [x1,x2,…,xn]，每个 xi∈Rdmodel，那么：

    yi=FFN(xi)

    对所有 i，共享同一组参数 W1,W2，但运算彼此独立。

- 这样既能保证处理序列时的并行性，又不破坏序列的顺序敏感性（因为Attention处理顺序信息）。

换句话说：

- **“Position-wise”强调它不跨位置，而不是它依赖位置**。
- 如果它叫“Token-wise FFN”可能更直观，但论文沿用了这个叫法。

------

### **总结一句话**

- **Attention** = 跨位置交互（建模序列依赖）。
- **FFN** = 每个位置独立非线性变换（建模局部特征）。
- “Position-wise”表示 **逐位置独立应用**，不是指和位置编码绑定。

------

✅ 要不要我帮你画一个 **示意图（Attention vs FFN 数据流）**，并用 **PyTorch写一个最小示例** 展示：

- 输入 batch × seq_len × d_model
- Position-wise FFN如何在不打乱序列的情况下工作？
    同时我可以比较一下如果**不使用FFN**，Transformer的表达能力会如何受限。要不要做这个？
